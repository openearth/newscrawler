#!/usr/bin/env python
import json
import logging
from contextlib import closing
import subprocess
import os


import geojson
import requests
import pika
import shapely.geometry

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

with open('settings.json') as f:
    settings = json.load(f)

host = settings['space.deltares.nl']['host']
credentials = pika.PlainCredentials(
    settings['space.deltares.nl']['username'],
    settings['space.deltares.nl']['password']
)
connection = pika.BlockingConnection(
    pika.ConnectionParameters(
        host,
        5672,
        '/',
        credentials
    )
)

channel = connection.channel()

# we're publishing to an exchange so that other's can listen
# to what has been downloaded
channel.exchange_declare(
    exchange='crisis_incident',
    type='fanout'
)

# forward the messages to a queue, remove after disconnect
result = channel.queue_declare(exclusive=True)
# with a name chosen by the server
queue_name = result.method.queue
# pass the results along to the new empty queue
channel.queue_bind(exchange='crisis_incident',
                   queue=result.method.queue)


def callback(channel, method, properties, body, *args, **kwargs):
    # ch, method, properties, body
    data = geojson.loads(body)
    logger.info("channel: %s\nargs: %s, kwargs: %s", channel, args, kwargs)
    logger.info("data: %s", data)
    geom = shapely.geometry.asShape(data['geometry'])
    logger.info("geom: %s", geom.wkt)

    end_date = data['properties']['endDate']
    begin_date = data['properties']['startDate']
    url = 'http://localhost:6800/schedule.json'
    data = {
        'project': 'default',
        'spider': 'newsspider',
        'polygon': geom,
	'begin_date': begin_date,
        'end_date': end_date
    }
    result = requests.post(url, data=data)
    logger.info('result: %s', result)

channel.basic_consume(callback,
                      queue=queue_name,
                      no_ack=True)
channel.start_consuming()
